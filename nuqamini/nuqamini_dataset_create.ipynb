{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74f422d4",
   "metadata": {},
   "source": [
    "# NuQA Mini Dataset Creator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e271f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import preparation\n",
    "\n",
    "from nuscenes.nuscenes import NuScenes\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageFilter, ImageEnhance\n",
    "import datasets\n",
    "import matplotlib.pyplot as pltq\n",
    "import pandas as pd\n",
    "import json\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import base64\n",
    "import random\n",
    "import torch\n",
    "import gc\n",
    "import copy\n",
    "import time\n",
    "import multiprocessing\n",
    "\n",
    "#from rangevit.rangevit_extract import RangeVitEncoderAltWrapper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530736d9",
   "metadata": {},
   "source": [
    "## NuscenesQA preparation\n",
    "\n",
    "* Nuscenes-QA: https://github.com/qiantianwen/NuScenes-QA\n",
    "* https://drive.google.com/drive/folders/1jIkICT23wZWZYPrWCa0x-ubjpClSzOuU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4745e54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nuscenes.nuscenes import NuScenes\n",
    "from nuscenes.utils.data_classes import LidarPointCloud\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageFilter, ImageEnhance\n",
    "from mini_lidar_dataset_creator import RangeProjection\n",
    "import numpy as np\n",
    "import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json\n",
    "import io\n",
    "import os\n",
    "import base64\n",
    "import random\n",
    "import pickle\n",
    "import torch\n",
    "import gc\n",
    "import copy\n",
    "from pathlib import Path\n",
    "import multiprocessing\n",
    "from torchvision.transforms.functional import center_crop\n",
    "import pyblur3\n",
    "\n",
    "\n",
    "\n",
    "class NuQAMiniDatasetCreator:\n",
    "    cam_directions = ['CAM_FRONT', 'CAM_FRONT_RIGHT', 'CAM_BACK_RIGHT',\n",
    "                      'CAM_BACK', 'CAM_BACK_LEFT', 'CAM_FRONT_LEFT']\n",
    "    \n",
    "    def __init__(self, version='v1.0-mini', path='data', lidarnpypath='data'):\n",
    "        self.nusc = NuScenes(version=version, dataroot=path, verbose=False)\n",
    "        self.lidarnpypath = lidarnpypath\n",
    "        self.scene_token_to_description = {}\n",
    "        for s in self.nusc.scene:\n",
    "            self.scene_token_to_description[s['token']] = s['description']\n",
    "\n",
    "                \n",
    "    def extract_matched_samples(self, split='train'):\n",
    "        mininuscene_sample_tokens = []\n",
    "\n",
    "        for sc in self.nusc.scene:\n",
    "            sample_token = sc['first_sample_token']\n",
    "            while len(sample_token) > 0:\n",
    "                sample = self.nusc.get('sample', sample_token)\n",
    "                sample_token = sample['next']\n",
    "                mininuscene_sample_tokens.append(sample_token)\n",
    "                \n",
    "        matched_count = 0\n",
    "        hop_0_count = 0\n",
    "        hop_1_count = 0\n",
    "        matched_samples = []\n",
    "\n",
    "        with open(f\"dataset/nuscenes-qa/NuScenes_{split}_questions.json\", \"r\") as json_file:\n",
    "            questions = json.loads(json_file.read())\n",
    "            for qa_sample in tqdm(questions['questions']):\n",
    "                if qa_sample['sample_token'] in mininuscene_sample_tokens:\n",
    "                    sample = self.nusc.get('sample', qa_sample['sample_token'])\n",
    "                    matched_samples.append({\n",
    "                        'scene description': self.scene_token_to_description[sample['scene_token']],\n",
    "                        'token': qa_sample['sample_token'],\n",
    "                        'data': sample['data'], \n",
    "                        'question': qa_sample['question'],\n",
    "                        'answer': qa_sample['answer'],\n",
    "                    })\n",
    "                    matched_count += 1\n",
    "                    if qa_sample['num_hop'] == 0:\n",
    "                        hop_0_count += 1\n",
    "                    elif qa_sample['num_hop'] == 1:\n",
    "                        hop_1_count += 1\n",
    "        print(f\"#### Extracted from {split} split:\")\n",
    "        print(f\"matched count = {matched_count}\")\n",
    "        print(f\"hop0 count = {hop_0_count}\")\n",
    "        print(f\"hop1 count = {hop_1_count}\")\n",
    "        return matched_samples\n",
    "    \n",
    "    \n",
    "    def simplify_scene_description(self, data):\n",
    "        for sample in data:\n",
    "            if 'Night' in sample['scene description']:\n",
    "                sample['scene description'] = 'night'\n",
    "            else:\n",
    "                sample['scene description'] = 'day'\n",
    "        return data\n",
    "    \n",
    "    \n",
    "    def summarize_scene_info(self, data):\n",
    "        total_count = 0\n",
    "        day_count = 0\n",
    "        night_count = 0\n",
    "        for sample in data:\n",
    "            if sample['scene description'] == 'night':\n",
    "                night_count += 1\n",
    "            else:\n",
    "                day_count += 1\n",
    "            total_count += 1\n",
    "        print('#####')\n",
    "        print(f\"day={day_count} ({day_count/total_count*100:.2f} %)\")\n",
    "        print(f\"night={night_count} ({night_count/total_count*100:.2f} %)\")\n",
    "        print(f\"total={total_count} (100 %)\")\n",
    "        \n",
    "    \n",
    "    def merge_and_distribute(self, train, val, seed=0):\n",
    "        random.seed(seed)\n",
    "        data = train + val\n",
    "        \n",
    "        day_samples = []\n",
    "        night_samples = []\n",
    "        for sample in data:\n",
    "            if sample['scene description'] == 'night':\n",
    "                night_samples += [sample]\n",
    "            else:\n",
    "                day_samples += [sample]\n",
    "                \n",
    "        random.shuffle(day_samples)\n",
    "        random.shuffle(night_samples)\n",
    "        \n",
    "        num_day_samples = len(day_samples)\n",
    "        num_night_samples = len(night_samples)\n",
    "        \n",
    "        day_train = day_samples[:num_day_samples // 2]\n",
    "        day_val = day_samples[num_day_samples // 2:]\n",
    "        night_train = night_samples[:num_night_samples // 2]\n",
    "        night_val = night_samples[num_night_samples // 2:]\n",
    "        \n",
    "        return day_train, day_val, night_train, night_val\n",
    "    \n",
    "    \n",
    "    # def process_img_and_lidar_v0(self, sample, cam_direction='CAM_FRONT'):\n",
    "    #     lidar_top = sample['data']['LIDAR_TOP']\n",
    "    #     cam = sample['data'][cam_direction]\n",
    "    #     points, coloring, im = self.nusc.explorer.map_pointcloud_to_image(\n",
    "    #         pointsensor_token=lidar_top,\n",
    "    #         camera_token=cam,\n",
    "    #     )\n",
    "    #     fig, ax = plt.subplots(1, 1, figsize=(9, 16))\n",
    "    #     ax.imshow(im)\n",
    "    #     image = self.ghost_savefig(fig)\n",
    "    #     ax.imshow(np.zeros_like(np.array(im))) # keep this line to use black background\n",
    "    #     ax.scatter(points[0, :], points[1, :], c=coloring, s=5, cmap='Greys') # adjust colar map?\n",
    "    #     lidar = self.ghost_savefig(fig) # lidar point clouds overlay image\n",
    "    #     plt.close(fig)\n",
    "    #     return image, lidar\n",
    "    \n",
    "    @classmethod\n",
    "    def process_image_nothing(self, im_raw):\n",
    "        im = np.array(im_raw.resize((224, 224)).convert('RGB'))#.tolist()\n",
    "        return im\n",
    "    \n",
    "    @classmethod\n",
    "    def process_image_halfdim(self, im_raw):\n",
    "        dim_enhancer = ImageEnhance.Brightness(im_raw)\n",
    "        # https://stackoverflow.com/questions/31360526/low-the-brightness-of-an-image-using-pillow\n",
    "        im1 = dim_enhancer.enhance(0.5)\n",
    "        im = np.array(im1.resize((224, 224)).convert('RGB'))\n",
    "        return im\n",
    "    \n",
    "    @classmethod\n",
    "    def process_image_80dim(self, im_raw):\n",
    "        dim_enhancer = ImageEnhance.Brightness(im_raw)\n",
    "        im1 = dim_enhancer.enhance(0.2)\n",
    "        im = np.array(im1.resize((224, 224)).convert('RGB'))\n",
    "        im2 = im1.resize((224, 224)).convert('RGB')\n",
    "        import time\n",
    "        t = time.time()\n",
    "        im_t = im_raw.resize((224, 224)).convert('RGB')\n",
    "        im2.save('test/{}_dim80.png'.format(t))\n",
    "        im_t.save('test/{}_orig.png'.format(t))\n",
    "        return im\n",
    "    \n",
    "    @classmethod\n",
    "    def process_image_80dim50contrast(self, im_raw):\n",
    "        dim_enhancer = ImageEnhance.Brightness(im_raw)\n",
    "        im1 = dim_enhancer.enhance(0.2)\n",
    "        contrast_enhancer = ImageEnhance.Contrast(im1)\n",
    "        im2 = contrast_enhancer.enhance(0.5)\n",
    "        im = np.array(im2.resize((224, 224)).convert('RGB'))\n",
    "\n",
    "        import time\n",
    "        t = time.time()\n",
    "        im2 = im1.resize((224, 224)).convert('RGB')\n",
    "        im_t = im_raw.resize((224, 224)).convert('RGB')\n",
    "        im2.save('test2/{}_dim80contrast50.png'.format(t))\n",
    "        im_t.save('test2/{}_orig.png'.format(t))\n",
    "\n",
    "        return im\n",
    "\n",
    "    @classmethod\n",
    "    def process_image_gaussian5(self, im_raw):\n",
    "        im1 = im_raw.filter(ImageFilter.GaussianBlur(radius = 5))\n",
    "        im = np.array(im1.resize((224, 224)).convert('RGB'))      \n",
    "        return im\n",
    "    \n",
    "    @classmethod\n",
    "    def process_image_80dimgaussian7(self, im_raw):\n",
    "        im1 = im_raw.filter(ImageFilter.GaussianBlur(radius = 7))\n",
    "        dim_enhancer = ImageEnhance.Brightness(im1)\n",
    "        im2 = dim_enhancer.enhance(0.2)\n",
    "        im3 = im2.resize((224, 224)).convert('RGB')\n",
    "        im = np.array(im3)\n",
    "        \n",
    "        t = time.time()\n",
    "        im_orig = im_raw.resize((224, 224)).convert('RGB')\n",
    "        im_orig.save('test4/{}_orig.png'.format(t))\n",
    "        im3.save('test4/{}_80dimgaussian7.png'.format(t))\n",
    "        \n",
    "        return im\n",
    "    \n",
    "    @classmethod\n",
    "    def process_image_defocus(self, im_raw):\n",
    "        kernelsize = 3\n",
    "        im1 = pyblur3.DefocusBlur(im_raw, kernelsize)\n",
    "        im2 = im1.resize((224, 224)).convert('RGB')\n",
    "        im = np.array(im2)\n",
    "        t = time.time()\n",
    "        im_orig = im_raw.resize((224, 224)).convert('RGB')\n",
    "        im_orig.save('test3/{}_orig.png'.format(t))\n",
    "        im2.save('test3/{}_defocus.png'.format(t))\n",
    "        return im\n",
    "        \n",
    "    \n",
    "    def process_image(self, sample, cam_direction='CAM_FRONT', vartype: str = None):\n",
    "        camera_token = sample['data'][cam_direction]\n",
    "        cam = self.nusc.get('sample_data', camera_token)\n",
    "        im_raw = Image.open(os.path.join(self.nusc.dataroot, cam['filename']))\n",
    "        \n",
    "        if vartype is None:\n",
    "            im = self.process_image_nothing(im_raw)\n",
    "        elif vartype == 'halfdim':\n",
    "            im = self.process_image_halfdim(im_raw)\n",
    "        elif vartype == 'gaussian5':\n",
    "            im = self.process_image_gaussian5(im_raw)\n",
    "        elif vartype == '80dim':\n",
    "            im = self.process_image_80dim(im_raw)\n",
    "        elif vartype == '80dim50contrast':\n",
    "            im = self.process_image_80dim50contrast(im_raw)\n",
    "        elif vartype == 'defocus':\n",
    "            im = self.process_image_defocus(im_raw)\n",
    "        elif vartype == '80dimgaussian7':\n",
    "            im = self.process_image_80dimgaussian7(im_raw)\n",
    "        else:\n",
    "            raise Exception('Unrecognized process_image() vartype! Aborting...')\n",
    "            \n",
    "        im_raw.close()\n",
    "        return im\n",
    "    \n",
    "    def process_lidar(self, sample):\n",
    "        pointsensor_token = sample['data']['LIDAR_TOP']\n",
    "        #print('pointsensor_token is: {}'.format(pointsensor_token)) # This is token name\n",
    "        # Read npy file, not list of list\n",
    "        lidar_filename = str(Path(self.lidarnpypath) / \"{}.npy\".format(pointsensor_token))\n",
    "        lidar_npy = np.load(lidar_filename)\n",
    "        return lidar_npy\n",
    "    \n",
    "    def ghost_savefig(self, fig):\n",
    "        '''Based on answers from https://stackoverflow.com/questions/8598673/'''\n",
    "        buf = io.BytesIO()\n",
    "        self.save(buf, fig=fig)\n",
    "        buf.seek(0)\n",
    "        im = Image.open(buf)\n",
    "        im = im.copy()\n",
    "        buf.close()\n",
    "        return im\n",
    "    \n",
    "    @staticmethod\n",
    "    def save(filepath=\"image.jpg\", format='jpg', fig=None):\n",
    "        '''Save the current image with no whitespace\n",
    "        Example filepath: \"myfig.png\" or r\"C:\\myfig.pdf\" \n",
    "        Based on answers from https://stackoverflow.com/questions/11837979/\n",
    "        '''\n",
    "        import matplotlib.pyplot as plt\n",
    "        if not fig:\n",
    "            fig = plt.gcf()\n",
    "            \n",
    "        plt.subplots_adjust(0,0,1,1,0,0)\n",
    "        for ax in fig.axes:\n",
    "            ax.axis('off')\n",
    "            ax.margins(0,0)\n",
    "            ax.xaxis.set_major_locator(plt.NullLocator())\n",
    "            ax.yaxis.set_major_locator(plt.NullLocator())\n",
    "        \n",
    "        fig.savefig(filepath, format=format, pad_inches=0, bbox_inches='tight')\n",
    "    \n",
    "    def create_arrow_v2(self, dataset, basepath, c1: str, c2: str, vartype: str = None):\n",
    "        print(\"#### Generating nuscenses_qa_mini::{}/{} dataset... (vartype: {})\".format(c1, c2, vartype))\n",
    "        path = str(Path(basepath) / c1 / c2)\n",
    "        data = {}\n",
    "        data['token'] = []\n",
    "        for cam in self.cam_directions:\n",
    "            data[cam] = []\n",
    "        data['LIDAR_TOP'] = []\n",
    "        data['question'] = []\n",
    "        data['answer'] = []\n",
    "        counter = 0\n",
    "        for idx, sample in enumerate(tqdm(dataset)):\n",
    "            data['token'] += [sample['token']]\n",
    "            for cam in self.cam_directions:\n",
    "                data[cam] += [self.process_image(sample, cam, vartype)]\n",
    "            data['question'] += [sample['question']]\n",
    "            data['answer'] += [sample['answer']]\n",
    "            data['LIDAR_TOP'] += [self.process_lidar(sample)]\n",
    "            counter = counter + 1\n",
    "\n",
    "        data_arrow = datasets.Dataset.from_dict(data)\n",
    "        data_arrow.save_to_disk(path)\n",
    "        print(\"#### Completed!\")\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0442db0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test():\n",
    "    out_path = 'nuscenes_qa_mini_224/'\n",
    "    ds = datasets.load_from_disk(out_path + 'train')\n",
    "    img = ds['CAM_FRONT_LIDAR_OVERLAY'][100]\n",
    "    print(type(img))\n",
    "    feature = datasets.Image(decode=True)\n",
    "    img = feature.decode_example(img)\n",
    "    img.show()\n",
    "    print(type(img.convert('RGB')))\n",
    "\n",
    "\n",
    "def make_dirs(dirs):\n",
    "    for d in dirs:\n",
    "        if not os.path.exists(d):\n",
    "            os.makedirs(d)\n",
    "\n",
    "\n",
    "def create_arrow_v2_parallel(ds_instance, exec_params, blocking=False):\n",
    "    '''\n",
    "    Example: ds.create_arrow_v2(night_train, out_path, c1='night', c2='train', vartype='halfdim')\n",
    "    '''\n",
    "    def mp_create_arrow_wrapper(ds, params):\n",
    "        i = params\n",
    "        ds.create_arrow_v2(i[0], i[1], c1=i[2], c2=i[3], vartype=i[4])\n",
    "        return\n",
    "    total_len = len(exec_params)\n",
    "    p_list = list()\n",
    "    for param_ref in exec_params:\n",
    "        param = copy.deepcopy(param_ref)\n",
    "        ds = copy.deepcopy(ds_instance)\n",
    "        p = multiprocessing.Process(target=mp_create_arrow_wrapper, args=(ds, param))\n",
    "        p.start()\n",
    "        p_list.append(p)\n",
    "    if blocking:\n",
    "        for p in p_list:\n",
    "            p.join()\n",
    "    print('\\n### Parallel create_arrow_v2 finished!\\n')\n",
    "    return\n",
    "\n",
    "\n",
    "def main():\n",
    "    out_path = 'nuscenes_qa_mini_withdim/'\n",
    "    make_dirs([\n",
    "        out_path,\n",
    "        # out_path + 'day',\n",
    "        # out_path + 'night',\n",
    "        # out_path + 'day_gaussian5',\n",
    "        # out_path + 'night_gaussian5',\n",
    "        # out_path + 'day_halfdim',\n",
    "        # out_path + 'night_halfdim',\n",
    "        out_path + 'night_80dim',\n",
    "        out_path + 'night_80dim50contrast',\n",
    "        out_path + 'night_defocus',\n",
    "        out_path + 'night_80dimgaussian7',\n",
    "    ])\n",
    "    ds = NuQAMiniDatasetCreator(\n",
    "        version='v1.0-mini', path='dataset/v1.0-mini/data/sets/nuscenes/',\n",
    "        lidarnpypath='dataset/v1.0-mini/data/sets/range_projection_outputs/')\n",
    "    # extract intersection between nuscenes-mini and nuscenes-qa\n",
    "    ds_train = ds.extract_matched_samples('train')\n",
    "    ds_val = ds.extract_matched_samples('val')\n",
    "    # refactor scene description\n",
    "    ds_train = ds.simplify_scene_description(ds_train)\n",
    "    ds_val = ds.simplify_scene_description(ds_val)\n",
    "    # merge and redistribute scenes\n",
    "    day_train, day_val, night_train, night_val = ds.merge_and_distribute(ds_train, ds_val, seed=123)\n",
    "    ds.summarize_scene_info(day_train)\n",
    "    ds.summarize_scene_info(day_val)\n",
    "    ds.summarize_scene_info(night_train)\n",
    "    ds.summarize_scene_info(night_val)\n",
    "    gc.collect()\n",
    "    # create arrow datasets\n",
    "    print(\"#### Generating arrows...\")\n",
    "\n",
    "    ## Regular data generation\n",
    "    exec_params_orig = [\n",
    "        (night_train, out_path, 'night', 'train', None),\n",
    "        (night_val, out_path, 'night', 'validation', None),\n",
    "        (day_train, out_path, 'day', 'train', None),\n",
    "        (day_val, out_path, 'day', 'validation', None),\n",
    "    ]\n",
    "    \n",
    "    # ## Variation of dimming: halfdim\n",
    "    exec_params_halfdim = [\n",
    "        (night_train, out_path, 'night_halfdim', 'train', 'halfdim'),\n",
    "        (night_val, out_path, 'night_halfdim', 'validation', 'halfdim'),\n",
    "        (day_train, out_path, 'day_halfdim', 'train', 'halfdim'),\n",
    "        (day_val, out_path, 'day_halfdim', 'validation', 'halfdim'),\n",
    "    ]\n",
    "    # create_arrow_v2_parallel(ds, exec_params2, blocking=False)\n",
    "  \n",
    "    # ## Variation of dimming: gaussian5\n",
    "    exec_params_gaussian5 = [\n",
    "        (night_train, out_path, 'night_gaussian5', 'train', 'gaussian5'),\n",
    "        (night_val, out_path, 'night_gaussian5', 'validation', 'gaussian5'),\n",
    "        (day_train, out_path, 'day_gaussian5', 'train', 'gaussian5'),\n",
    "        (day_val, out_path, 'day_gaussian5', 'validation', 'guassian5'),\n",
    "    ]\n",
    "    \n",
    "    ## Variation of dimming: 80dim\n",
    "    exec_params_80dim = [\n",
    "        #(night_train, out_path, 'night_80dim', 'train', '80dim'),\n",
    "        #(night_val, out_path, 'night_80dim', 'validation', '80dim'),\n",
    "        #(night_train, out_path, 'night_80dim50contrast', 'train', '80dim50contrast'),\n",
    "        #(night_val, out_path, 'night_80dim50contrast', 'validation', '80dim50contrast'),\n",
    "    ]\n",
    "    exec_params_80dimgaussian7 = [\n",
    "        (night_train, out_path, 'night_80dimgaussian7', 'train', '80dimgaussian7'),\n",
    "        (night_val, out_path, 'night_80dimgaussian7', 'validation', '80dimgaussian7'),\n",
    "        (day_train, out_path, 'day', 'train', None),\n",
    "        (day_val, out_path, 'day', 'validation', None),\n",
    "    ]\n",
    "    \n",
    "    ## Execution (actual)\n",
    "    create_arrow_v2_parallel(ds, exec_params_80dimgaussian7, blocking=True)\n",
    "    \n",
    "    # TODO: modify create_arrow() and resize() methods, option to downscale brightness\n",
    "    return ds\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ds = main()\n",
    "\n",
    "    # load_test()\n",
    "    # create_dataset_with_resized_images(split='train')\n",
    "    # create_dataset_with_resized_images(split='validation')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
